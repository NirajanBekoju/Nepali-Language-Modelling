{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlCbFiAZMXh4",
        "outputId": "1d54bbca-ddbd-4d2f-d3aa-3f995ef91260"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "OR8zfjFpcQR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib"
      ],
      "metadata": {
        "id": "tKtOlNG6oH-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import PlaintextCorpusReader"
      ],
      "metadata": {
        "id": "EhN3Ao3PL8UV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nepali Unicode Converter"
      ],
      "metadata": {
        "id": "2k8VEHgim8jm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nepali-unicode-converter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNlzExnUne2D",
        "outputId": "0e54b5ff-2d69-49a3-bda3-98eca3a2564f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nepali-unicode-converter in /usr/local/lib/python3.7/dist-packages (1.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nepali_unicode_converter.convert import Converter\n",
        "converter = Converter()\n",
        "my_string = 'mero desha'\n",
        "converted_string = converter.convert(my_string)\n",
        "print(converted_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVBfTttFGFkR",
        "outputId": "515cbc56-c621-439d-dba2-b218e49d86a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "मेरो देश\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read and explore data"
      ],
      "metadata": {
        "id": "cKSQKJ_6a41J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wordlists = PlaintextCorpusReader(\"/content/drive/MyDrive/Colab Notebooks/NLP/Language Modelling/Datasets/Nepali_Corpus\", '.*txt')"
      ],
      "metadata": {
        "id": "bZn_ok6QMqtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts,invalid = [],0\n",
        "for i in tqdm(wordlists.fileids()):\n",
        "    try:\n",
        "        texts.append(wordlists.raw(i).replace(\"\\ufeff\",\"\"))\n",
        "    except UnicodeDecodeError:\n",
        "        invalid+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_zqYc7bML6S",
        "outputId": "c03c287e-fbb4-4b90-9a68-b79a8c89cc0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6592/6592 [50:57<00:00,  2.16it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(wordlists.fileids())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n56ES8F-MLar",
        "outputId": "3bae5528-d3fc-497e-c832-d8685fcf3d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6592"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7d3st4-YVKk",
        "outputId": "51ea223b-d156-4688-ebe8-9a1321964bbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(texts), invalid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDksMXcLYU-I",
        "outputId": "8900b93a-d76f-431f-e9ac-fd61e010b631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6592 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(texts, \"/content/drive/MyDrive/Colab Notebooks/NLP/Language Modelling/Datasets/Nepali_Corpus/texts_list.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiiWtlmqYU2Y",
        "outputId": "fccb569d-bc70-4007-b9cf-c93e83f6fc51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Colab Notebooks/NLP/Language Modelling/Datasets/Nepali_Corpus/texts_list.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = joblib.load(\"/content/drive/MyDrive/Colab Notebooks/NLP/Language Modelling/Datasets/Nepali_Corpus/texts_list.pkl\")"
      ],
      "metadata": {
        "id": "J5bhCAM2YUuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "vETGxmLtZYOd",
        "outputId": "b6264d9a-2f1b-4c67-e788-451d3d1211ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'न्यूयोर्क—गैरआवासिय नेपाली संघ अमेरिकाको पाँचौ साधारणसभा जनवरी १४ कादिन टेक्सासमा हुने भएको छ। साधारण सभाको उद्घाटन गर्न नेपालबाट परराष्टमन्त्री डा.प्रकाशशरण महत आउने कार्यक्रम रहेको एनआरएन अमेरिकाका अध्यक्ष डा.केशव पौडेलले बताए।\\nअमेरिकामा उम्मेदवारी दिने क्रम शुरु भएको छ। अमेरिकामा सदस्यता वृद्धि भएकोले विधान परिवर्तन गर्नुपर्ने आवाज उठेको छ।\\xa0\\nसाधारणसभामा संगठन विस्तारकालागिअत्याधिक नेपालीलाई सदस्यताका लागि पहल गर्ने, विधान संशोधनको विषय, अमेरिकाको न्यूजर्सीमा सम्पन्न क्षेत्रीय सम्मेलनका क्रममा उठेको एनआरएन भिजन २०२० को कार्यन्वय नगर्ने विषयमाथि छलफल गरिनेछ। आगामी नयाँ नेतृत्व छान्ने अधिवेसनको आधार तय गर्न पनि यो साधारण सभाले महत्व राख्ने छ।\\nजसका लागि यतिखेर अमेरिकामा उम्मेदवारी दिने क्रम शुरु भएको छ। अमेरिकामा सदस्यता वृद्धि भएकोले विधान परिवर्तन गर्नुपर्ने आवाज उठेको छ।\\xa0\\nगैरआवासिय नेपाली संघको एनसिसिहरुमा सबै भन्दा ठूलो अमेरिकामा १० हजार ७ सय साधारण सदस्यहरु छन्। अमेरिकामा रहेका नेपालीहरुको संख्या हिसावले यो पनि कम सदस्य हुन्। अमेरिकामा करिब २ लाख ८० हजार नेपाली छन्।\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(texts[1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFahX9W9ZYMV",
        "outputId": "1ee654c0-1f2e-415e-e52b-a0962c26b9f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "न्यूयोर्क—गैरआवासिय नेपाली संघ अमेरिकाको पाँचौ साधारणसभा जनवरी १४ कादिन टेक्सासमा हुने भएको छ। साधारण सभाको उद्घाटन गर्न नेपालबाट परराष्टमन्त्री डा.प्रकाशशरण महत आउने कार्यक्रम रहेको एनआरएन अमेरिकाका अध्यक्ष डा.केशव पौडेलले बताए।\n",
            "अमेरिकामा उम्मेदवारी दिने क्रम शुरु भएको छ। अमेरिकामा सदस्यता वृद्धि भएकोले विधान परिवर्तन गर्नुपर्ने आवाज उठेको छ। \n",
            "साधारणसभामा संगठन विस्तारकालागिअत्याधिक नेपालीलाई सदस्यताका लागि पहल गर्ने, विधान संशोधनको विषय, अमेरिकाको न्यूजर्सीमा सम्पन्न क्षेत्रीय सम्मेलनका क्रममा उठेको एनआरएन भिजन २०२० को कार्यन्वय नगर्ने विषयमाथि छलफल गरिनेछ। आगामी नयाँ नेतृत्व छान्ने अधिवेसनको आधार तय गर्न पनि यो साधारण सभाले महत्व राख्ने छ।\n",
            "जसका लागि यतिखेर अमेरिकामा उम्मेदवारी दिने क्रम शुरु भएको छ। अमेरिकामा सदस्यता वृद्धि भएकोले विधान परिवर्तन गर्नुपर्ने आवाज उठेको छ। \n",
            "गैरआवासिय नेपाली संघको एनसिसिहरुमा सबै भन्दा ठूलो अमेरिकामा १० हजार ७ सय साधारण सदस्यहरु छन्। अमेरिकामा रहेका नेपालीहरुको संख्या हिसावले यो पनि कम सदस्य हुन्। अमेरिकामा करिब २ लाख ८० हजार नेपाली छन्।\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XQa0ox85gYW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split texts into the list of sentences"
      ],
      "metadata": {
        "id": "aoPv-QygganA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "##Split in text\n",
        "paragraph = list()\n",
        "for text in texts:\n",
        "    raw = re.split(r\"\\n|\\r\",text.strip())\n",
        "    if len(text) > 0 or not re.match('(\\s)+',text): \n",
        "        paragraph.extend(raw)\n",
        "print(len(paragraph))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNmrlRnuZYKC",
        "outputId": "58e95f3a-36cb-41f0-e426-f31db618ffea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph[1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "qw2C9tKcZXlc",
        "outputId": "d297f243-49e3-40e8-8388-0d85390ba875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'भुवनले छोरा अनमोल केसीको अभिनय रहेको ‘कृ’का लागि आफूले खेलेको लोकप्रिय फिल्म ‘सम्झना’को लोकप्रिय गीतको एक टुक्रा प्रयोग गरेका थिए । ‘कृ’मा रहेको ‘धेरैपछि सम्झना, आँखा छोपी बसन’ बोलको गीतमा ‘उकालीमा अघिअघि’को टुक्रा पुरानै धुनमा समावेश गरिएको छ । अनुमति नै नलिई गीत राखेको भन्दै ‘सम्झना’ फिल्मका निर्देशक शम्भु प्रधान प्रहरी कार्यालय पुगेका हुन् ।\\xa0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Into Sentences based on purna biram\n",
        "pura_sents = []\n",
        "for i in paragraph:\n",
        "    pura_sents.extend(re.split(r'(?<=।)\\s',i))\n",
        "print(len(pura_sents))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ddxdQZrZXgy",
        "outputId": "bac9e1c3-2195-46db-b003-acaa7144c3c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "207449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pura_sents[1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "roie-F1RZXb-",
        "outputId": "7fee9cc3-442b-4676-bdc4-6c8fe92014c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'मधुबाला हिन्दी फिल्मकी सर्वकालिक उम्दा नायिकाका रूपमा चिनिन्छिन्।'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split sentence based on question mark\n",
        "purna_prasna_sents = []\n",
        "for i in pura_sents:\n",
        "    purna_prasna_sents.extend(re.split(r'(?<=\\?)\\s',i))\n",
        "#sents\n",
        "print(len(purna_prasna_sents))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52W8GsBhZ81F",
        "outputId": "92424fbc-f8b3-4db6-ef38-fe438c1094ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "211586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split sentences baseed on exclamation\n",
        "sents = []\n",
        "for i in purna_prasna_sents:\n",
        "    sents.extend(re.split(r'(?<=\\!)\\s',i))\n",
        "#sents\n",
        "print(len(sents))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caiknAbTZ8wo",
        "outputId": "e11c74d0-99b0-4c20-9017-fee34ad113e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "212186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ord('a')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CmIZDBjbhTQ",
        "outputId": "53a05b47-14a1-4c33-d45a-1dddd7e2911a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chr(97)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gLs0eXY2bhOS",
        "outputId": "c798558e-4539-47ed-9fb2-f1d8d817dd9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ord('म')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRUOkAH_cF__",
        "outputId": "bfcb355d-ac84-4d3e-d003-4cfe47bbd5a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2350"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chr(2350)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6yJel8IWbgiS",
        "outputId": "2294cd27-8431-4968-c8a3-a80817f768a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'म'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Removing Non-devanagari letters\n",
        "\n",
        "Devaganari characters has ascii vale from decimal 2304 to 2431 and in hexa 0900 to 097F"
      ],
      "metadata": {
        "id": "YbASCkh9cZv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "non_dev_nagari = []\n",
        "for i in sents:\n",
        "    for j in i:\n",
        "        #Devanagari range \n",
        "        if not 0x0090 <= ord(j) <= 0x97F: \n",
        "            non_dev_nagari.append(j)"
      ],
      "metadata": {
        "id": "K3HxbEKQZ8r9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_candidates = set(non_dev_nagari)"
      ],
      "metadata": {
        "id": "LqvJP7s5arfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\\u200d is ZWJ\n",
        "#\\xa0 is non breaking space\n",
        "remove_candidates-={\" \",\"!\",\"(\",\")\",\"–\",\"’\",\"‘\",\",\",\".\",\"?\",\"-\",\"/\",\":\",\"“\",\"”\",\"\\u200d\",\"\\xa0\",\"'\"}\n",
        "\n",
        "remove_candidates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcKkXTK8arba",
        "outputId": "ba9c8366-62fd-499f-bb25-e9a696e9099b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\"',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " '*',\n",
              " '+',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ';',\n",
              " '<',\n",
              " '=',\n",
              " '>',\n",
              " '@',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '_',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '{',\n",
              " '|',\n",
              " '}',\n",
              " '~',\n",
              " '\\x81',\n",
              " '\\x8d',\n",
              " '১',\n",
              " '\\u200b',\n",
              " '\\u200c',\n",
              " '‐',\n",
              " '—',\n",
              " '„',\n",
              " '•',\n",
              " '…',\n",
              " '\\u2028',\n",
              " '\\u2029',\n",
              " '\\u202f',\n",
              " '‰',\n",
              " '′',\n",
              " '›',\n",
              " '│',\n",
              " '┐',\n",
              " '┬',\n",
              " '╕',\n",
              " '╖',\n",
              " '╛',\n",
              " '╜',\n",
              " '╡',\n",
              " '╢',\n",
              " '╣',\n",
              " '░',\n",
              " '▓',\n",
              " '◊',\n",
              " '☔',\n",
              " '✨',\n",
              " '❤',\n",
              " '⭐',\n",
              " '\\uf02d',\n",
              " '\\uf0a7'}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "invalid_char_sents = []\n",
        "chr_valid_sents = []\n",
        "for i in sents:\n",
        "    invalid = False\n",
        "    invalid_chars = set()\n",
        "    for j in i:\n",
        "        #Devanagari range \n",
        "        if j in remove_candidates: \n",
        "            invalid = True\n",
        "            invalid_chars.update((j))\n",
        "    if invalid :\n",
        "        invalid_char_sents.append(i+\"**\"+\"*\".join(invalid_chars)) #For filtering\n",
        "    else:\n",
        "        chr_valid_sents.append(i)\n",
        "len(invalid_char_sents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ2XrEz0arXc",
        "outputId": "6d0c549c-f7e6-4991-f958-59ad7b35cddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1910"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Remove Puntuation..#I know I should use regex...But it was easir to do it this way :D\n",
        "#(\",\")\",\"–\",\"’\",\"‘\",\",\",\".\",\"?\",\"-\",\"/\",\":\",\"“\",\"”\",\"\\u200d\",\"\\xa0\",\"'\"\n",
        "punct_removed_sents = []\n",
        "for i in chr_valid_sents:\n",
        "    punct_removed_sents.append(i.replace(\"'\",\"\")\n",
        "                              .replace(',',\" \")\n",
        "                                .replace('’',\"\")\n",
        "                               .replace('‘',\"\")\n",
        "                               .replace('–',\" \")\n",
        "                               .replace('\\xa0',\" \")#Space Character \n",
        "                               .replace(\"'\",\"\")\n",
        "                               .replace(\"“\",\"\")\n",
        "                               .replace(\"”\",\"\")\n",
        "                               .replace(\"-\",\"\")\n",
        "                               .replace(\"?\",\"\")\n",
        "                               .replace(\"।\",\"\")\n",
        "                               .replace(\"!\",\"\")\n",
        "                              )"
      ],
      "metadata": {
        "id": "PHcHJQTvarRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(punct_removed_sents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqBGRObedlmM",
        "outputId": "2947ec11-9330-494b-b538-3f79806d1c4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210276"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(punct_removed_sents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tczuUTHndoSe",
        "outputId": "b26bb84a-4baf-4dba-8b59-2eb6ab25865d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(punct_removed_sents[1000])\n",
        "print(punct_removed_sents[90000])\n",
        "print(punct_removed_sents[3000])\n",
        "print(punct_removed_sents[3400])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlmevG4Jgsqx",
        "outputId": "62a85395-a470-4bcd-aae9-dfb27d9dca61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "काठमाडौं   नेपाली साहित्य विकास परिषद युकेका वरिष्ठ सहअध्यक्ष कोमल मल्लको कविता सङ्ग्रह म देश लेख्छु को विमोचन गरिएको छ\n",
            "प्रयोगशाला जोखिम भत्ता\n",
            "श्रवण मुकारुङको बिसे नगर्चीको बयान लोकतन्त्रपछिको सबैभन्दा चर्चित कविता हो\n",
            "घमण्ड गर्ने मेरो संस्कार छँदैछैन र गर्दिन पनि \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove the unnecessary spaces and empty sentences\n",
        "def filter(sentences):\n",
        "  return [re.sub(' +', ' ', sentence) for sentence in sentences if len(sentence) > 0]\n",
        "\n",
        "tmp_sentences = ['धादिङ    नेपालसहित ११ देशका कलाकारले धादिङ महोत्सवमा प्रस्तुती देखाएका छन्', '']\n",
        "filter(tmp_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2mYPGU4eQy7",
        "outputId": "f5e030a1-ec49-4347-cc22-7fcad03b89d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['धादिङ नेपालसहित ११ देशका कलाकारले धादिङ महोत्सवमा प्रस्तुती देखाएका छन्']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_sentences = filter(punct_removed_sents)"
      ],
      "metadata": {
        "id": "bKA1w8cleQs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(filtered_sentences, \"/content/drive/MyDrive/Colab Notebooks/NLP/Language Modelling/Datasets/Nepali_Corpus/final_sentences.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZbuDXc_eQkM",
        "outputId": "bdc9b871-b1e3-4f8e-b27a-5419053c8047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Colab Notebooks/NLP/Language Modelling/Datasets/Nepali_Corpus/final_sentences.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_sentences = joblib.load(\"/content/drive/MyDrive/Colab Notebooks/NLP/Language Modelling/Datasets/Nepali_Corpus/final_sentences.pkl\")"
      ],
      "metadata": {
        "id": "MlvJi7cGfniS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(final_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_UU_Dupfv2D",
        "outputId": "b456b338-c160-48b3-a0d3-a5d5081cbe13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "198000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_sentences[1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uCoxDqOIft69",
        "outputId": "385a4d8f-71e8-4abb-88c8-f4236257cb3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'दृश्य खिच्दै गर्दा दिलिपकुमारले मधुबालालाई साँच्चिकै थप्पड हानिदिए'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_sentences[10000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "S6xqJFcigA6q",
        "outputId": "d00aaf81-c82b-49de-abcc-9094d7f94aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'२०७२ बैसाख १२ गते गएको भूकम्पमा परेर लाङटाङमा तीन सय भन्दा बढीले ज्यान गुमाएका थिए'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Removing numbers from the text corpus\n",
        "\n",
        "Ascii value of 0 in devanagari is 2406 i.e unicode hex: U+0966\n",
        "\n",
        "Ascii value of 9 in devanagarai is 2415 i.e unicode hex: U+096F"
      ],
      "metadata": {
        "id": "tqzEAhIzhgVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ord('१')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbCcg7ISiAKq",
        "outputId": "56bf0b0c-4a4d-48a0-87bb-e326c6ad4b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2407"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_sent = \"२०७२ बैसाख १२ गते गएको भूकम्पमा परेर लाङटाङमा तीन सय भन्दा बढीले ज्यान गुमाएका थिए\"\n",
        "tmp_sent_1 = \"मकवानपुर फिल्म हुर्रेले रिलिज मिति नजिकिएसँगै प्रचारप्रसारमा तीव्रता दिएको छ \""
      ],
      "metadata": {
        "id": "nkrWsqTniv6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tmp_sent.split(\" \"))\n",
        "print(tmp_sent_1.split(\" \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEzTVpH-i11F",
        "outputId": "e4a54932-053f-471f-e21d-fee7a0786cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['२०७२', 'बैसाख', '१२', 'गते', 'गएको', 'भूकम्पमा', 'परेर', 'लाङटाङमा', 'तीन', 'सय', 'भन्दा', 'बढीले', 'ज्यान', 'गुमाएका', 'थिए']\n",
            "['मकवानपुर', 'फिल्म', 'हुर्रेले', 'रिलिज', 'मिति', 'नजिकिएसँगै', 'प्रचारप्रसारमा', 'तीव्रता', 'दिएको', 'छ', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_sent_1.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcXg7OH0lFIC",
        "outputId": "a0d1374b-5477-4a01-cdd0-76e72724d9f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['मकवानपुर',\n",
              " 'फिल्म',\n",
              " 'हुर्रेले',\n",
              " 'रिलिज',\n",
              " 'मिति',\n",
              " 'नजिकिएसँगै',\n",
              " 'प्रचारप्रसारमा',\n",
              " 'तीव्रता',\n",
              " 'दिएको',\n",
              " 'छ']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_sent.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFIOTce0lNbS",
        "outputId": "17d4d034-10d7-49a7-c16d-e74f5c856d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['२०७२',\n",
              " 'बैसाख',\n",
              " '१२',\n",
              " 'गते',\n",
              " 'गएको',\n",
              " 'भूकम्पमा',\n",
              " 'परेर',\n",
              " 'लाङटाङमा',\n",
              " 'तीन',\n",
              " 'सय',\n",
              " 'भन्दा',\n",
              " 'बढीले',\n",
              " 'ज्यान',\n",
              " 'गुमाएका',\n",
              " 'थिए']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(word for word in tmp_sent_1.split() if not 2406 <= ord(word[0]) <= 2415)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cm07_ZuGksr8",
        "outputId": "0e2fcad0-2e3b-4a80-e68e-ebb25aabe6d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'मकवानपुर फिल्म हुर्रेले रिलिज मिति नजिकिएसँगै प्रचारप्रसारमा तीव्रता दिएको छ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(word for word in tmp_sent.split() if not 2406 <= ord(word[0]) <= 2415)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WPK6OgbHi1yz",
        "outputId": "9a75e3cf-16f5-44f4-cf81-07ca087844c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'बैसाख गते गएको भूकम्पमा परेर लाङटाङमा तीन सय भन्दा बढीले ज्यान गुमाएका थिए'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_numbers(sentences):\n",
        "  tmp_sentences = []\n",
        "  for sentence in sentences:\n",
        "    # remove the leading and the trailing spaces and check if first letter of word is a number or not\n",
        "    new_sent = ' '.join(word for word in sentence.split() if not 2406 <= ord(word[0]) <= 2415)\n",
        "    tmp_sentences.append(new_sent)\n",
        "  return tmp_sentences"
      ],
      "metadata": {
        "id": "-Q8hT6VTi1wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_removed_numbers = remove_numbers(final_sentences)"
      ],
      "metadata": {
        "id": "Ek4BOzgDiADg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sent_removed_numbers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vikyN9OxlipF",
        "outputId": "8be5be4a-7c00-4288-e324-7deb14625985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "198000"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_removed_numbers[10000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hi-TCuTVl0FY",
        "outputId": "e4aa4675-20d1-42fa-b549-7ff78b03774d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'बैसाख गते गएको भूकम्पमा परेर लाङटाङमा तीन सय भन्दा बढीले ज्यान गुमाएका थिए'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_removed_numbers[1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gJWJuOVxhfhi",
        "outputId": "204a8f19-728d-420b-de5e-330d7124c18e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'दृश्य खिच्दै गर्दा दिलिपकुमारले मधुबालालाई साँच्चिकै थप्पड हानिदिए'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize the sentences"
      ],
      "metadata": {
        "id": "GSaQ2S6Wes7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_sentences(sentences):\n",
        "  \"\"\"\n",
        "  convert the sentences list into the tokenized form\n",
        "\n",
        "  Input: sentences\n",
        "  Output: list of tokenized words list of sentences\n",
        "  \"\"\"\n",
        "  tokenized_sentences = []\n",
        "  print(\"Tokenizing sentences...\")\n",
        "  for sentence in tqdm(sentences):\n",
        "    tokenized = nltk.word_tokenize(sentence)\n",
        "    tokenized_sentences.append(tokenized)\n",
        "  \n",
        "  return tokenized_sentences"
      ],
      "metadata": {
        "id": "LOhKR_hzfW18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences = tokenize_sentences(sent_removed_numbers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzf0iCUZmB4x",
        "outputId": "e4a6d690-5f5d-4a79-d452-faa28126ca52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing sentences...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 198000/198000 [00:45<00:00, 4324.74it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_sentences[1000])\n",
        "print(tokenized_sentences[10000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RsavmaCmQ2C",
        "outputId": "66e22d9a-f7cc-45db-fd13-c89e45c169fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['दृश्य', 'खिच्दै', 'गर्दा', 'दिलिपकुमारले', 'मधुबालालाई', 'साँच्चिकै', 'थप्पड', 'हानिदिए']\n",
            "['बैसाख', 'गते', 'गएको', 'भूकम्पमा', 'परेर', 'लाङटाङमा', 'तीन', 'सय', 'भन्दा', 'बढीले', 'ज्यान', 'गुमाएका', 'थिए']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(tokenized_sentences, \"/content/drive/MyDrive/Colab Notebooks/NLP/Language Modelling/Datasets/Nepali_Corpus/tokenized_sentences.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46CW3q5ELNXw",
        "outputId": "299cacdd-8c3d-4952-f524-768e1ec48cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Colab Notebooks/NLP/Language Modelling/Datasets/Nepali_Corpus/tokenized_sentences.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences = joblib.load(\"/content/drive/MyDrive/Colab Notebooks/NLP/Language Modelling/Datasets/Nepali_Corpus/tokenized_sentences.pkl\")"
      ],
      "metadata": {
        "id": "mJSLY-sPLVyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split into train and test data"
      ],
      "metadata": {
        "id": "4M4Nbk-qh40_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_data = tokenized_sentences\n",
        "random.seed(101)\n",
        "random.shuffle(tokenized_data)\n",
        "\n",
        "train_size = int(len(tokenized_data) * 0.9)\n",
        "train_data = tokenized_data[0:train_size]\n",
        "test_data = tokenized_data[train_size:]"
      ],
      "metadata": {
        "id": "t_d9SCnqqlm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{len(tokenized_data)} are split into {len(train_data)} train and {len(test_data)} test set\")\n",
        "\n",
        "print(\"First Training sample: \")\n",
        "print(train_data[0])\n",
        "print(\"First Test Sample: \")\n",
        "print(test_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS_KL6hRqlge",
        "outputId": "e3f7842a-b8b5-4106-ab13-2ca9fae0e2d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "198000 are split into 178200 train and 19800 test set\n",
            "First Training sample: \n",
            "['ऐलानी', 'जग्गामा', 'बस्ने', 'उनीहरूसँग', 'लालपुर्जा', 'छैन']\n",
            "First Test Sample: \n",
            "['ना', 'ख', 'नम्बरको', 'बाह्र', 'चक्के', 'ट्रकले', 'पैदल', 'हिँड्दै', 'गरेका', 'सोही', 'ठाउँमा', 'वर्षीय', 'चन्द्रमान', 'श्रेष्ठलाई', 'ठक्कर', 'दिँदा', 'उनको', 'घटनास्थलमै', 'ज्यान', 'गएको', 'ट्राफिक', 'प्रमुख', 'दयाराम', 'पौडेलले', 'बताए']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_words(tokenized_sentences):\n",
        "  \"\"\"\n",
        "  Count the number of word appearances in the tokenized sentences\n",
        "  \"\"\"\n",
        "\n",
        "  word_counts = {}\n",
        "  for sentence in tokenized_sentences:\n",
        "    for token in sentence:\n",
        "      if token not in word_counts.keys():\n",
        "        word_counts[token] = 1\n",
        "      else:\n",
        "        word_counts[token] += 1\n",
        "  \n",
        "\n",
        "  return word_counts"
      ],
      "metadata": {
        "id": "g3aTU0DXqlcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences = [['sky', 'is', 'blue', '.'],\n",
        "                       ['leaves', 'are', 'green', '.'],\n",
        "                       ['roses', 'are', 'red', '.']]\n",
        "count_words(tokenized_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrdFqyuwqlUi",
        "outputId": "691eb70a-eee6-4df6-beef-b7e965aade5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sky': 1,\n",
              " 'is': 1,\n",
              " 'blue': 1,\n",
              " '.': 3,\n",
              " 'leaves': 1,\n",
              " 'are': 2,\n",
              " 'green': 1,\n",
              " 'roses': 1,\n",
              " 'red': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling OUt of Vocabulary words"
      ],
      "metadata": {
        "id": "eg7UrTzesG5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_words_with_nplus_frequency(tokenized_sentences, count_threshold):\n",
        "  closed_vocab = []\n",
        "\n",
        "  word_counts = count_words(tokenized_sentences)\n",
        "\n",
        "  for word, cnt in word_counts.items():\n",
        "    if cnt >= count_threshold:\n",
        "      closed_vocab.append(word)\n",
        "  \n",
        "  return closed_vocab"
      ],
      "metadata": {
        "id": "4qSgQuzgr7wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences = [['sky', 'is', 'blue', '.'],\n",
        "                       ['leaves', 'are', 'green', '.'],\n",
        "                       ['roses', 'are', 'red', '.']]\n",
        "tmp_closed_vocab = get_words_with_nplus_frequency(tokenized_sentences, count_threshold=2)\n",
        "print(f\"Closed vocabulary:\")\n",
        "print(tmp_closed_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bd3QJpBHsbkR",
        "outputId": "7902457c-99de-444d-fd9f-a521b6d29ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closed vocabulary:\n",
            "['.', 'are']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_oov_words_by_unk(tokenized_sentences, vocabulary, unknown_token = \"<unk>\"):\n",
        "  \"\"\"\n",
        "  Replaced all the words in tokenized_sentences not in vocabulary by the unknown_token\n",
        "  \"\"\"\n",
        "  \n",
        "  vocabulary = set(vocabulary)\n",
        "\n",
        "  replaced_tokenized_sentences = []\n",
        "\n",
        "  for sentence in tokenized_sentences:\n",
        "    replaced_sentence = []\n",
        "\n",
        "    for token in sentence:\n",
        "      if token in vocabulary:\n",
        "        replaced_sentence.append(token)\n",
        "      else:\n",
        "        replaced_sentence.append(unknown_token)\n",
        "    replaced_tokenized_sentences.append(replaced_sentence)\n",
        "  \n",
        "  return replaced_tokenized_sentences"
      ],
      "metadata": {
        "id": "TQY9_4wNseqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences = [[\"dogs\", \"run\"], [\"cats\", \"sleep\"]]\n",
        "vocabulary = [\"dogs\", \"sleep\"]\n",
        "tmp_replaced_tokenized_sentences = replace_oov_words_by_unk(tokenized_sentences, vocabulary)\n",
        "\n",
        "print(f\"Original sentence:\")\n",
        "print(tokenized_sentences)\n",
        "print(f\"tokenized_sentences with less frequent words converted to '<unk>':\")\n",
        "print(tmp_replaced_tokenized_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRZbuRtwtG7D",
        "outputId": "23add9b1-14ba-4650-a893-5da9926deded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence:\n",
            "[['dogs', 'run'], ['cats', 'sleep']]\n",
            "tokenized_sentences with less frequent words converted to '<unk>':\n",
            "[['dogs', '<unk>'], ['<unk>', 'sleep']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(train_data, test_data, count_threshold):\n",
        "  vocabulary = get_words_with_nplus_frequency(train_data, count_threshold)\n",
        "\n",
        "  train_data_replaced = replace_oov_words_by_unk(train_data, vocabulary)\n",
        "\n",
        "  test_data_replaced = replace_oov_words_by_unk(test_data, vocabulary)\n",
        "\n",
        "  return train_data_replaced, test_data_replaced, vocabulary"
      ],
      "metadata": {
        "id": "JcOON2SLtKEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_train = [['sky', 'is', 'blue', '.'], ['leaves', 'are', 'green']]\n",
        "tmp_test = [['roses', 'are', 'red', '.']]\n",
        "\n",
        "tmp_train_repl, tmp_test_repl, tmp_vocab = preprocess_data(tmp_train, tmp_test, count_threshold = 1)\n",
        "\n",
        "print(\"tmp_train_repl\")\n",
        "print(tmp_train_repl)\n",
        "print()\n",
        "print(\"tmp_test_repl\")\n",
        "print(tmp_test_repl)\n",
        "print()\n",
        "print(\"tmp_vocab\")\n",
        "print(tmp_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSFqO4L2tPMk",
        "outputId": "8a6fad3d-240d-4469-89ff-6fdc533459af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tmp_train_repl\n",
            "[['sky', 'is', 'blue', '.'], ['leaves', 'are', 'green']]\n",
            "\n",
            "tmp_test_repl\n",
            "[['<unk>', 'are', '<unk>', '.']]\n",
            "\n",
            "tmp_vocab\n",
            "['sky', 'is', 'blue', '.', 'leaves', 'are', 'green']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "minimum_freq = 2\n",
        "train_data_processed, test_data_processed, vocabulary = preprocess_data(train_data, test_data, minimum_freq)"
      ],
      "metadata": {
        "id": "1wdqsrGptv9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First preprocessed training sample:\")\n",
        "print(\"Original Sentence : \", train_data[0])\n",
        "print(train_data_processed[0])\n",
        "print()\n",
        "print(\"First preprocessed test sample:\")\n",
        "print(\"Original Sentence : \", test_data[0])\n",
        "print(test_data_processed[0])\n",
        "print()\n",
        "print(\"First 10 vocabulary:\")\n",
        "print(vocabulary[0:10])\n",
        "print()\n",
        "print(\"Size of vocabulary:\", len(vocabulary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsPJp1gzt-2U",
        "outputId": "f0c189d6-10dd-4f37-e441-14fb6c4fec58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First preprocessed training sample:\n",
            "Original Sentence :  ['ऐलानी', 'जग्गामा', 'बस्ने', 'उनीहरूसँग', 'लालपुर्जा', 'छैन']\n",
            "['ऐलानी', 'जग्गामा', 'बस्ने', 'उनीहरूसँग', 'लालपुर्जा', 'छैन']\n",
            "\n",
            "First preprocessed test sample:\n",
            "Original Sentence :  ['ना', 'ख', 'नम्बरको', 'बाह्र', 'चक्के', 'ट्रकले', 'पैदल', 'हिँड्दै', 'गरेका', 'सोही', 'ठाउँमा', 'वर्षीय', 'चन्द्रमान', 'श्रेष्ठलाई', 'ठक्कर', 'दिँदा', 'उनको', 'घटनास्थलमै', 'ज्यान', 'गएको', 'ट्राफिक', 'प्रमुख', 'दयाराम', 'पौडेलले', 'बताए']\n",
            "['ना', 'ख', 'नम्बरको', 'बाह्र', '<unk>', 'ट्रकले', 'पैदल', 'हिँड्दै', 'गरेका', 'सोही', 'ठाउँमा', 'वर्षीय', 'चन्द्रमान', 'श्रेष्ठलाई', 'ठक्कर', 'दिँदा', 'उनको', 'घटनास्थलमै', 'ज्यान', 'गएको', 'ट्राफिक', 'प्रमुख', 'दयाराम', 'पौडेलले', 'बताए']\n",
            "\n",
            "First 10 vocabulary:\n",
            "['ऐलानी', 'जग्गामा', 'बस्ने', 'उनीहरूसँग', 'लालपुर्जा', 'छैन', 'धेरै', 'कारोबार', 'कार्डबाट', 'हुने']\n",
            "\n",
            "Size of vocabulary: 80552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Develop a n gram based language model"
      ],
      "metadata": {
        "id": "12VIMFqHumB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_n_grams(data, n, start_token = \"<s>\", end_token = \"</s>\"):\n",
        "  \"\"\"\n",
        "  Count all the n-grams of the data\n",
        "  \"\"\"\n",
        "\n",
        "  n_grams = {}\n",
        "\n",
        "  for sentence in data:\n",
        "    # prepend start token n times and append end token one time\n",
        "    sentence = [start_token] * n + sentence + [end_token]\n",
        "\n",
        "    # convert list to tuple so that the sequence of words can be used as a key in the dictionary\n",
        "    sentence = tuple(sentence)\n",
        "\n",
        "    # use value of m to denote the number of n grams in the current sentence\n",
        "    m = len(sentence) if n==1 else len(sentence) - 1\n",
        "\n",
        "    for i in range(m):\n",
        "      n_gram = sentence[i: i + n]\n",
        "\n",
        "      # check if the n-gram is in the dictionary\n",
        "      # if present, increase the value else se the value of n-gram to 1\n",
        "      if n_gram in n_grams.keys():\n",
        "        n_grams[n_gram] += 1\n",
        "      else:\n",
        "        n_grams[n_gram] = 1\n",
        "\n",
        "  return n_grams\n"
      ],
      "metadata": {
        "id": "F0fvrJ3JuDGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [['i', 'like', 'a', 'cat'],\n",
        "             ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
        "print(\"Uni-gram:\")\n",
        "print(count_n_grams(sentences, 1))\n",
        "print(\"Bi-gram:\")\n",
        "print(count_n_grams(sentences, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CobVz4nsvhLH",
        "outputId": "1f795b8f-5546-46f3-f0ab-b0ced4f7c0bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uni-gram:\n",
            "{('<s>',): 2, ('i',): 1, ('like',): 2, ('a',): 2, ('cat',): 2, ('</s>',): 2, ('this',): 1, ('dog',): 1, ('is',): 1}\n",
            "Bi-gram:\n",
            "{('<s>', '<s>'): 2, ('<s>', 'i'): 1, ('i', 'like'): 1, ('like', 'a'): 2, ('a', 'cat'): 2, ('cat', '</s>'): 2, ('<s>', 'this'): 1, ('this', 'dog'): 1, ('dog', 'is'): 1, ('is', 'like'): 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_probability(word, previous_n_gram, n_gram_counts, n_plus1_gram_counts, vocabulary_size, k = 1.0):\n",
        "  \"\"\"\n",
        "  Estimate the probabilities of the next word using the n-gram counts with k-smoothing\n",
        "  \"\"\"\n",
        "\n",
        "  # convert the list to tuple to use it as a dictionary key\n",
        "  previous_n_gram = tuple(previous_n_gram)\n",
        "\n",
        "  # set the denominator\n",
        "  # if the previous n-gram exists in the dictionary of n-gram counts, get its coun\n",
        "  # else set the count to zero\n",
        "  # use the dictionary that has counts for n-grams\n",
        "  previous_n_gram_count = n_gram_counts[previous_n_gram] if previous_n_gram in n_gram_counts else 0\n",
        "\n",
        "  # calculate the denominator useing the count fo the previous n gram and apply k-smoothing\n",
        "  denominator = previous_n_gram_count + k * vocabulary_size\n",
        "\n",
        "  # define n plus 1 gram as the previous n-gram plus the current word as a tuple\n",
        "  n_plus1_gram = previous_n_gram + (word, )\n",
        "\n",
        "  # set the count to the count in the dictionary\n",
        "  # 0 if not in the dictionary\n",
        "  # use the dictionary that has counts for the n-gram plus current word\n",
        "  n_plus1_gram_count = n_plus1_gram_counts[n_plus1_gram] if n_plus1_gram in n_plus1_gram_counts else 0\n",
        "\n",
        "  # define the numerator using the counf of the n-gram plus current word and apply smoothing\n",
        "  numerator = n_plus1_gram_count + k\n",
        "\n",
        "  # calculate the probability as the numberator divided by the denominator\n",
        "  probability = numerator / denominator\n",
        "\n",
        "  return probability"
      ],
      "metadata": {
        "id": "Oa3s4078T_vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [['i', 'like', 'a', 'cat'],\n",
        "             ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
        "unique_words = list(set(sentences[0] + sentences[1]))\n",
        "\n",
        "unigram_counts = count_n_grams(sentences, 1)\n",
        "bigram_counts = count_n_grams(sentences, 2)\n",
        "tmp_prob = estimate_probability(\"cat\", \"a\", unigram_counts, bigram_counts, len(unique_words), k=1)\n",
        "\n",
        "print(f\"The estimated probability of word 'cat' given the previous n-gram 'a' is: {tmp_prob:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzDJJatcvvAO",
        "outputId": "d6090041-e4cc-4064-d5cd-e4f1f59e3c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimated probability of word 'cat' given the previous n-gram 'a' is: 0.3333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_probabilities(previous_n_gram, n_gram_counts, n_plus1_gram_counts, vocabulary, k = 1.0):\n",
        "  \"\"\"\n",
        "  Estimate the probabilities of next words using the n-gram counts with k-smoothing\n",
        "  \"\"\"\n",
        "  # convert the list to tuple to use it as a dictionary key\n",
        "  previous_n_gram = tuple(previous_n_gram)\n",
        "\n",
        "  # add </s> and <unk> to the vocabulary\n",
        "  # <s> is not needed as it should not appear as the next word\n",
        "  vocabulary = vocabulary + [\"</s>\", \"<unk>\"]\n",
        "  vocabular_size = len(vocabulary)\n",
        "\n",
        "  probabilities = {}\n",
        "  for word in vocabulary:\n",
        "    probability = estimate_probability(word, previous_n_gram, n_gram_counts, n_plus1_gram_counts, vocabular_size, k = k)\n",
        "    probabilities[word] = probability\n",
        "  \n",
        "  return probabilities"
      ],
      "metadata": {
        "id": "ZhLvo34Uv4OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [['i', 'like', 'a', 'cat'],\n",
        "             ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
        "unique_words = list(set(sentences[0] + sentences[1]))\n",
        "unigram_counts = count_n_grams(sentences, 1)\n",
        "bigram_counts = count_n_grams(sentences, 2)\n",
        "estimate_probabilities(\"a\", unigram_counts, bigram_counts, unique_words, k=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1JqAK3uwJm5",
        "outputId": "d9fe75f3-cf75-4e3d-b58e-36cab25571de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cat': 0.2727272727272727,\n",
              " 'dog': 0.09090909090909091,\n",
              " 'is': 0.09090909090909091,\n",
              " 'this': 0.09090909090909091,\n",
              " 'a': 0.09090909090909091,\n",
              " 'like': 0.09090909090909091,\n",
              " 'i': 0.09090909090909091,\n",
              " '</s>': 0.09090909090909091,\n",
              " '<unk>': 0.09090909090909091}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Count and Probability matrices"
      ],
      "metadata": {
        "id": "s0f6bJchwfXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_count_matrix(n_plus1_gram_counts, vocabulary):\n",
        "  # add </s> and <UNK> to the vocabulary\n",
        "  # <s> is omitted since it should not appear as next word\n",
        "  vocabulary = vocabulary + [\"</s>\", \"<UNK>\"]\n",
        "\n",
        "  # obtain unique n-grams from n_plus1_gram_counts\n",
        "  n_grams = []\n",
        "  for n_plus1_gram in n_plus1_gram_counts.keys():\n",
        "    # n_gram is from first to second last words of n_plus1_gram\n",
        "    n_gram = n_plus1_gram[0:-1]\n",
        "    n_grams.append(n_gram)\n",
        "  n_grams = list(set(n_grams))\n",
        "\n",
        "  # mapping from n-gram to row\n",
        "  row_index = {n_gram : i for i, n_gram in enumerate(n_grams)}\n",
        "\n",
        "  # mapping from next word to column\n",
        "  col_index = {word : j for j, word in enumerate(vocabulary)}\n",
        "\n",
        "  # No. of rows = No. of n_grams\n",
        "  # No. of columns = No. of vocabulary\n",
        "  nrow = len(n_grams)\n",
        "  ncol = len(vocabulary)\n",
        "\n",
        "  # Initialize the count matrix of zeros with nrow and ncol\n",
        "  count_matrix = np.zeros((nrow, ncol))\n",
        "\n",
        "  # creating a count matrix from n_plus1_gram_counts\n",
        "  for n_plus1_gram, count in n_plus1_gram_counts.items():\n",
        "    n_gram = n_plus1_gram[0:-1]\n",
        "    word = n_plus1_gram[-1]\n",
        "    if word not in vocabulary:\n",
        "      continue\n",
        "    i = row_index[n_gram]\n",
        "    j = col_index[word]\n",
        "    count_matrix[i, j] = count\n",
        "\n",
        "  # Creating dataframe of count matrix\n",
        "  count_matrix = pd.DataFrame(count_matrix, index = n_grams, columns = vocabulary)\n",
        "\n",
        "  return count_matrix"
      ],
      "metadata": {
        "id": "80-QqKDcwNBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [['i', 'like', 'a', 'cat'], ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
        "unique_words = list(set(sentences[0] + sentences[1]))\n",
        "bigram_counts = count_n_grams(sentences, 2)\n",
        "\n",
        "print('bigram counts')\n",
        "display(make_count_matrix(bigram_counts, unique_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "vIlS4XtwwjjO",
        "outputId": "66990a90-dedf-4689-9a86-f1bc6a4f0df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigram counts\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         cat  dog   is  this    a  like    i  </s>  <UNK>\n",
              "(cat,)   0.0  0.0  0.0   0.0  0.0   0.0  0.0   2.0    0.0\n",
              "(i,)     0.0  0.0  0.0   0.0  0.0   1.0  0.0   0.0    0.0\n",
              "(dog,)   0.0  0.0  1.0   0.0  0.0   0.0  0.0   0.0    0.0\n",
              "(is,)    0.0  0.0  0.0   0.0  0.0   1.0  0.0   0.0    0.0\n",
              "(this,)  0.0  1.0  0.0   0.0  0.0   0.0  0.0   0.0    0.0\n",
              "(a,)     2.0  0.0  0.0   0.0  0.0   0.0  0.0   0.0    0.0\n",
              "(<s>,)   0.0  0.0  0.0   1.0  0.0   0.0  1.0   0.0    0.0\n",
              "(like,)  0.0  0.0  0.0   0.0  2.0   0.0  0.0   0.0    0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0376a9f8-29ac-46d2-9e2c-cb5e6a0e0b18\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cat</th>\n",
              "      <th>dog</th>\n",
              "      <th>is</th>\n",
              "      <th>this</th>\n",
              "      <th>a</th>\n",
              "      <th>like</th>\n",
              "      <th>i</th>\n",
              "      <th>&lt;/s&gt;</th>\n",
              "      <th>&lt;UNK&gt;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>(cat,)</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(i,)</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(dog,)</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(is,)</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(this,)</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(a,)</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(&lt;s&gt;,)</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(like,)</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0376a9f8-29ac-46d2-9e2c-cb5e6a0e0b18')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0376a9f8-29ac-46d2-9e2c-cb5e6a0e0b18 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0376a9f8-29ac-46d2-9e2c-cb5e6a0e0b18');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_probability_matrix(n_plus1_gram_counts, vocabulary, k):\n",
        "  count_matrix = make_count_matrix(n_plus1_gram_counts, vocabulary)\n",
        "  # constant is added to each value in count_matrix to make its probability non-zero\n",
        "  count_matrix += k \n",
        "  prob_matrix = count_matrix.div(count_matrix.sum(axis = 1), axis = 0)\n",
        "  return prob_matrix"
      ],
      "metadata": {
        "id": "kyyknZH7wmwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [['i', 'like', 'a', 'cat'], ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
        "unique_words = list(set(sentences[0] + sentences[1]))\n",
        "bigram_counts = count_n_grams(sentences, 2)\n",
        "print(\"bigram probabilities\")\n",
        "display(make_probability_matrix(bigram_counts, unique_words, k=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "2H2dMVYvxUzR",
        "outputId": "1627721c-0e89-4459-ea47-3a126037a22a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigram probabilities\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              cat       dog        is      this         a      like         i  \\\n",
              "(cat,)   0.090909  0.090909  0.090909  0.090909  0.090909  0.090909  0.090909   \n",
              "(i,)     0.100000  0.100000  0.100000  0.100000  0.100000  0.200000  0.100000   \n",
              "(dog,)   0.100000  0.100000  0.200000  0.100000  0.100000  0.100000  0.100000   \n",
              "(is,)    0.100000  0.100000  0.100000  0.100000  0.100000  0.200000  0.100000   \n",
              "(this,)  0.100000  0.200000  0.100000  0.100000  0.100000  0.100000  0.100000   \n",
              "(a,)     0.272727  0.090909  0.090909  0.090909  0.090909  0.090909  0.090909   \n",
              "(<s>,)   0.090909  0.090909  0.090909  0.181818  0.090909  0.090909  0.181818   \n",
              "(like,)  0.090909  0.090909  0.090909  0.090909  0.272727  0.090909  0.090909   \n",
              "\n",
              "             </s>     <UNK>  \n",
              "(cat,)   0.272727  0.090909  \n",
              "(i,)     0.100000  0.100000  \n",
              "(dog,)   0.100000  0.100000  \n",
              "(is,)    0.100000  0.100000  \n",
              "(this,)  0.100000  0.100000  \n",
              "(a,)     0.090909  0.090909  \n",
              "(<s>,)   0.090909  0.090909  \n",
              "(like,)  0.090909  0.090909  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dbb19916-a5f4-4210-ad86-59d18292ee7e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cat</th>\n",
              "      <th>dog</th>\n",
              "      <th>is</th>\n",
              "      <th>this</th>\n",
              "      <th>a</th>\n",
              "      <th>like</th>\n",
              "      <th>i</th>\n",
              "      <th>&lt;/s&gt;</th>\n",
              "      <th>&lt;UNK&gt;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>(cat,)</th>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(i,)</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(dog,)</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(is,)</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(this,)</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(a,)</th>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(&lt;s&gt;,)</th>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(like,)</th>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbb19916-a5f4-4210-ad86-59d18292ee7e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dbb19916-a5f4-4210-ad86-59d18292ee7e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dbb19916-a5f4-4210-ad86-59d18292ee7e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"trigram probabilities\")\n",
        "trigram_counts = count_n_grams(sentences, 3)\n",
        "display(make_probability_matrix(trigram_counts, unique_words, k=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "uDEZHwQUxYBg",
        "outputId": "bdea2058-40c3-498b-c359-4793e1baff4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trigram probabilities\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                  cat       dog        is      this         a      like  \\\n",
              "(a, cat)     0.090909  0.090909  0.090909  0.090909  0.090909  0.090909   \n",
              "(<s>, i)     0.100000  0.100000  0.100000  0.100000  0.100000  0.200000   \n",
              "(cat,)       0.090909  0.090909  0.090909  0.090909  0.090909  0.090909   \n",
              "(this, dog)  0.100000  0.100000  0.200000  0.100000  0.100000  0.100000   \n",
              "(<s>, this)  0.100000  0.200000  0.100000  0.100000  0.100000  0.100000   \n",
              "(i, like)    0.100000  0.100000  0.100000  0.100000  0.200000  0.100000   \n",
              "(is, like)   0.100000  0.100000  0.100000  0.100000  0.200000  0.100000   \n",
              "(<s>, <s>)   0.090909  0.090909  0.090909  0.181818  0.090909  0.090909   \n",
              "(dog, is)    0.100000  0.100000  0.100000  0.100000  0.100000  0.200000   \n",
              "(like, a)    0.272727  0.090909  0.090909  0.090909  0.090909  0.090909   \n",
              "\n",
              "                    i      </s>     <UNK>  \n",
              "(a, cat)     0.090909  0.272727  0.090909  \n",
              "(<s>, i)     0.100000  0.100000  0.100000  \n",
              "(cat,)       0.090909  0.272727  0.090909  \n",
              "(this, dog)  0.100000  0.100000  0.100000  \n",
              "(<s>, this)  0.100000  0.100000  0.100000  \n",
              "(i, like)    0.100000  0.100000  0.100000  \n",
              "(is, like)   0.100000  0.100000  0.100000  \n",
              "(<s>, <s>)   0.181818  0.090909  0.090909  \n",
              "(dog, is)    0.100000  0.100000  0.100000  \n",
              "(like, a)    0.090909  0.090909  0.090909  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8e78d7b-2eac-4e01-afd4-f23834f25555\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cat</th>\n",
              "      <th>dog</th>\n",
              "      <th>is</th>\n",
              "      <th>this</th>\n",
              "      <th>a</th>\n",
              "      <th>like</th>\n",
              "      <th>i</th>\n",
              "      <th>&lt;/s&gt;</th>\n",
              "      <th>&lt;UNK&gt;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>(a, cat)</th>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(&lt;s&gt;, i)</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(cat,)</th>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(this, dog)</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(&lt;s&gt;, this)</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(i, like)</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(is, like)</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(&lt;s&gt;, &lt;s&gt;)</th>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(dog, is)</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(like, a)</th>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8e78d7b-2eac-4e01-afd4-f23834f25555')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8e78d7b-2eac-4e01-afd4-f23834f25555 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8e78d7b-2eac-4e01-afd4-f23834f25555');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def suggest_a_word(previous_tokens, n_gram_counts, n_plus1_gram_counts, vocabulary, k = 1.0, start_with = None):\n",
        "  \"\"\"\n",
        "  Get suggestion for the next word\n",
        "  \"\"\"\n",
        "\n",
        "  # length of previous words\n",
        "  n = len(list(n_gram_counts.keys())[0])\n",
        "\n",
        "  # From the words that the user already typed, get the most recent 'n' words as the previous n-gram\n",
        "  previous_n_gram = previous_tokens[-n:]\n",
        "\n",
        "  # Estimate the probabilities that each word in the vocabular is the next word\n",
        "  probabilities = estimate_probabilities(previous_n_gram, n_gram_counts, n_plus1_gram_counts, vocabulary, k = k)\n",
        "  \n",
        "  # Words with highest probability will be set to suggestion\n",
        "  suggestion = None\n",
        "\n",
        "  # Initialie the value for maximum probability\n",
        "  max_prob = 0\n",
        "\n",
        "  # For each word and its probability in the probabilities dictionary\n",
        "  for word, prob in probabilities.items():\n",
        "    # if the optional start with string is set\n",
        "    if start_with != None:\n",
        "      # Check if the beginning of word does not match with the letters in 'start_with'\n",
        "      if not word.startswith(start_with):\n",
        "        # if they don't match, skip this word and move onto the next word\n",
        "        continue\n",
        "\n",
        "    # Check if this word's probability is greater than the current maximum probability\n",
        "    if prob > max_prob:\n",
        "      # if so, save this word for the best suggestion\n",
        "      suggestion = word\n",
        "      max_prob = prob\n",
        "  \n",
        "  return suggestion, max_prob"
      ],
      "metadata": {
        "id": "w9tg776Ky1J4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [['i', 'like', 'a', 'cat'],\n",
        "             ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
        "unique_words = list(set(sentences[0] + sentences[1]))\n",
        "\n",
        "unigram_counts = count_n_grams(sentences, 1)\n",
        "bigram_counts = count_n_grams(sentences, 2)\n",
        "\n",
        "previous_tokens = [\"i\", \"like\"]\n",
        "tmp_suggest1 = suggest_a_word(previous_tokens, unigram_counts, bigram_counts, unique_words, k=1.0)\n",
        "print(f\"The previous words are 'i like',\\n\\tand the suggested word is `{tmp_suggest1[0]}` with a probability of {tmp_suggest1[1]:.4f}\")\n",
        "\n",
        "print()\n",
        "# test your code when setting the starts_with\n",
        "tmp_starts_with = 'c'\n",
        "tmp_suggest2 = suggest_a_word(previous_tokens, unigram_counts, bigram_counts, unique_words, k=1.0, start_with=tmp_starts_with)\n",
        "print(f\"The previous words are 'i like', the suggestion must start with `{tmp_starts_with}`\\n\\tand the suggested word is `{tmp_suggest2[0]}` with a probability of {tmp_suggest2[1]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P___9HsQzGDG",
        "outputId": "3b3e9c9c-5cd0-4139-95e5-2e1ad2cd724c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The previous words are 'i like',\n",
            "\tand the suggested word is `a` with a probability of 0.2727\n",
            "\n",
            "The previous words are 'i like', the suggestion must start with `c`\n",
            "\tand the suggested word is `cat` with a probability of 0.0909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_suggestions(previous_tokens, n_gram_counts_list, vocabulary, k = 1.0, start_with = None):\n",
        "  # different model means different n_gram\n",
        "  model_counts = len(n_gram_counts_list)\n",
        "  suggestions = []\n",
        "\n",
        "  for i in range(model_counts - 1):\n",
        "    n_gram_counts = n_gram_counts_list[i]\n",
        "    n_plus1_gram_counts = n_gram_counts_list[i + 1]\n",
        "\n",
        "    suggestion = suggest_a_word(previous_tokens, n_gram_counts, n_plus1_gram_counts, vocabulary, k = k, start_with = start_with)\n",
        "\n",
        "    suggestions.append(suggestion)\n",
        "\n",
        "  return suggestions"
      ],
      "metadata": {
        "id": "OteHXY1pzMOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [['i', 'like', 'a', 'cat'],\n",
        "             ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
        "unique_words = list(set(sentences[0] + sentences[1]))\n",
        "\n",
        "unigram_counts = count_n_grams(sentences, 1)\n",
        "bigram_counts = count_n_grams(sentences, 2)\n",
        "trigram_counts = count_n_grams(sentences, 3)\n",
        "quadgram_counts = count_n_grams(sentences, 4)\n",
        "qintgram_counts = count_n_grams(sentences, 5)\n",
        "\n",
        "n_gram_counts_list = [unigram_counts, bigram_counts, trigram_counts, quadgram_counts, qintgram_counts]\n",
        "previous_tokens = [\"i\", \"like\"]\n",
        "tmp_suggest3 = get_suggestions(previous_tokens, n_gram_counts_list, unique_words, k=1.0)\n",
        "\n",
        "print(f\"The previous words are 'i like', the suggestions are:\")\n",
        "display(tmp_suggest3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "InoMLQ7EzTn_",
        "outputId": "d83b7f48-ea71-4c4e-ed2b-8f5fcb5f21dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The previous words are 'i like', the suggestions are:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('a', 0.2727272727272727),\n",
              " ('a', 0.2),\n",
              " ('cat', 0.1111111111111111),\n",
              " ('cat', 0.1111111111111111)]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking above suggestions manually\n",
        "sentences = [['i', 'like', 'a', 'cat'],\n",
        "             ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
        "unigram_counts = count_n_grams(sentences, 1)\n",
        "bigram_counts = count_n_grams(sentences, 2)\n",
        "trigram_counts = count_n_grams(sentences, 3)\n",
        "quadgram_counts = count_n_grams(sentences, 4)\n",
        "qintgram_counts = count_n_grams(sentences, 5)\n",
        "\n",
        "display(make_probability_matrix(bigram_counts, unique_words, k=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "EvlEfCuBzWGI",
        "outputId": "5bb5ecf0-50d1-4804-8542-e35fc95fff2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              cat       dog        is      this         a      like         i  \\\n",
              "(cat,)   0.090909  0.090909  0.090909  0.090909  0.090909  0.090909  0.090909   \n",
              "(i,)     0.100000  0.100000  0.100000  0.100000  0.100000  0.200000  0.100000   \n",
              "(dog,)   0.100000  0.100000  0.200000  0.100000  0.100000  0.100000  0.100000   \n",
              "(is,)    0.100000  0.100000  0.100000  0.100000  0.100000  0.200000  0.100000   \n",
              "(this,)  0.100000  0.200000  0.100000  0.100000  0.100000  0.100000  0.100000   \n",
              "(a,)     0.272727  0.090909  0.090909  0.090909  0.090909  0.090909  0.090909   \n",
              "(<s>,)   0.090909  0.090909  0.090909  0.181818  0.090909  0.090909  0.181818   \n",
              "(like,)  0.090909  0.090909  0.090909  0.090909  0.272727  0.090909  0.090909   \n",
              "\n",
              "             </s>     <UNK>  \n",
              "(cat,)   0.272727  0.090909  \n",
              "(i,)     0.100000  0.100000  \n",
              "(dog,)   0.100000  0.100000  \n",
              "(is,)    0.100000  0.100000  \n",
              "(this,)  0.100000  0.100000  \n",
              "(a,)     0.090909  0.090909  \n",
              "(<s>,)   0.090909  0.090909  \n",
              "(like,)  0.090909  0.090909  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de776a97-54d2-4710-8d4b-b6e52b19edb2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cat</th>\n",
              "      <th>dog</th>\n",
              "      <th>is</th>\n",
              "      <th>this</th>\n",
              "      <th>a</th>\n",
              "      <th>like</th>\n",
              "      <th>i</th>\n",
              "      <th>&lt;/s&gt;</th>\n",
              "      <th>&lt;UNK&gt;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>(cat,)</th>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(i,)</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(dog,)</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(is,)</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(this,)</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(a,)</th>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(&lt;s&gt;,)</th>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(like,)</th>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de776a97-54d2-4710-8d4b-b6e52b19edb2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-de776a97-54d2-4710-8d4b-b6e52b19edb2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-de776a97-54d2-4710-8d4b-b6e52b19edb2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Suggest multiple words using n-gram of varying length"
      ],
      "metadata": {
        "id": "fuuakdbz0UXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_processed[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJMQn_6n0mUr",
        "outputId": "fd0b957a-6eae-44b0-81e3-92f4d554afb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ऐलानी', 'जग्गामा', 'बस्ने', 'उनीहरूसँग', 'लालपुर्जा', 'छैन']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_gram_counts_list = []\n",
        "for n in tqdm(range(1, 6)):\n",
        "  print(\"computing n-gram counts with n = \", n, \"....\")\n",
        "  n_model_counts = count_n_grams(train_data_processed, n)\n",
        "  n_gram_counts_list.append(n_model_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9aF339xz786",
        "outputId": "02c37ffb-061e-4ded-9e88-cbd9cae30f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computing n-gram counts with n =  1 ....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 1/5 [00:02<00:10,  2.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computing n-gram counts with n =  2 ....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:06<00:09,  3.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computing n-gram counts with n =  3 ....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [00:09<00:06,  3.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computing n-gram counts with n =  4 ....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [00:12<00:03,  3.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computing n-gram counts with n =  5 ....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:15<00:00,  3.19s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocabulary[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHinY0iAJM2C",
        "outputId": "e0a8f553-2d7a-4bbd-cf45-75e52fdca448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ऐलानी', 'जग्गामा', 'बस्ने', 'उनीहरूसँग', 'लालपुर्जा']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previous_tokens = ['दरबारमार्गमा', 'शोरुम']\n",
        "tmp_suggest4 = get_suggestions(previous_tokens, n_gram_counts_list, vocabulary, k=1.0)\n",
        "\n",
        "print(f\"The previous words are {previous_tokens}, the suggestions are:\")\n",
        "display(tmp_suggest4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "O6jecFAO0uLc",
        "outputId": "f1c67c5d-91a3-44c9-e74f-2a95ba39e443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The previous words are ['दरबारमार्गमा', 'शोरुम'], the suggestions are:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('खोलेको', 2.482744922786633e-05),\n",
              " ('ऐलानी', 1.2414032822702784e-05),\n",
              " ('ऐलानी', 1.2414032822702784e-05),\n",
              " ('ऐलानी', 1.2414032822702784e-05)]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tu23ra8809AY",
        "outputId": "8389cc5e-e641-4c71-9535-417eb6b1d182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ना', 'ख', 'नम्बरको', 'बाह्र', 'चक्के', 'ट्रकले', 'पैदल', 'हिँड्दै', 'गरेका', 'सोही', 'ठाउँमा', 'वर्षीय', 'चन्द्रमान', 'श्रेष्ठलाई', 'ठक्कर', 'दिँदा', 'उनको', 'घटनास्थलमै', 'ज्यान', 'गएको', 'ट्राफिक', 'प्रमुख', 'दयाराम', 'पौडेलले', 'बताए']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtCNjbTVHwSe",
        "outputId": "c69c31bd-e907-46a6-af8e-572051f67823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['ऐलानी', 'जग्गामा', 'बस्ने', 'उनीहरूसँग', 'लालपुर्जा', 'छैन'], ['धेरै', 'कारोबार', 'क्रेडिट÷डेबिट', 'कार्डबाट', 'हुने', 'हुँदा', 'यसको', 'सुरक्षण', 'प्रणाली', 'दरिलो', 'नभएमा', 'ठगी', 'र', 'अपचलन', 'रहन', 'सक्छ'], ['फलस्वरुप', 'पुनर्निर्माण', 'प्राविधिक', 'र', 'व्यापारिक', 'माखेसाङ्लोमा', 'जकडिन', 'पुग्यो'], ['उपहार', 'पार्सल', 'गरी', 'पठाएको', 'जानकारी', 'दिएर', 'बिदामा', 'बसेका', 'ती', 'युवा', 'उनले', 'रकम', 'पठाएको', 'भोलिपल्टबाटै', 'सामाजिक', 'सञ्जालबाट', 'हराए'], ['आर्थिक', 'समृद्धिको', 'अर्को', 'आधारका', 'रुपमा', 'रहेको', 'ऊर्जा', 'क्षेत्रमा', 'समेत', 'लगानीको', 'मात्रा', 'बढेको', 'विभागले', 'जनाएको', 'छ']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previous_tokens = ['ऊर्जा']\n",
        "suggestions = get_suggestions(previous_tokens, n_gram_counts_list, vocabulary, k=1.0)\n",
        "\n",
        "print(f\"The previous words are {previous_tokens}, the suggestions are:\")\n",
        "display(tmp_suggest4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "HrtbctWfGms9",
        "outputId": "37bf5f7e-aec1-448a-b359-b370690eeaa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The previous words are ['ऊर्जा'], the suggestions are:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('</s>', 0.0063799731369552125),\n",
              " ('<unk>', 7.44130669345537e-05),\n",
              " ('ऐलानी', 1.2414032822702784e-05),\n",
              " ('ऐलानी', 1.2414032822702784e-05)]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previous_tokens = ['त्यो', 'त']\n",
        "tmp_suggest4 = get_suggestions(previous_tokens, n_gram_counts_list, vocabulary, k=1.0)\n",
        "\n",
        "print(f\"The previous words are {previous_tokens}, the suggestions are:\")\n",
        "display(tmp_suggest4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "1xYDo6VT1JrW",
        "outputId": "d34b9c38-85f4-40aa-9008-e5861326f945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The previous words are ['त्यो', 'त'], the suggestions are:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('</s>', 0.0063799731369552125),\n",
              " ('<unk>', 7.44130669345537e-05),\n",
              " ('ऐलानी', 1.2414032822702784e-05),\n",
              " ('ऐलानी', 1.2414032822702784e-05)]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perplexity"
      ],
      "metadata": {
        "id": "7HSJnEPVD-xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_perplexity(sentence, n_gram_counts, n_plus1_gram_counts, vocabulary_size, k = 1.0):\n",
        "  \"\"\"\n",
        "  calculate the perplexity for a list of sentences\n",
        "  \"\"\"\n",
        "  # length of previous words\n",
        "  n = len(list(n_gram_counts.keys())[0])\n",
        "\n",
        "  # prepend <s> and append </s>\n",
        "  sentence = [\"<s>\"] * n + sentence + [\"</s>\"]\n",
        "\n",
        "  # cast the sentence from a list to a tuple\n",
        "  sentence = tuple(sentence)\n",
        "\n",
        "  # length of sentence (after adding)\n",
        "  N = len(sentence)\n",
        "\n",
        "  # The variable p will hold hte product that is calculated inside the n-root \n",
        "  # Update this in the code below\n",
        "  product_pi = 1.0\n",
        "\n",
        "  # index t ranges from n to N-1, inclusive on both ends\n",
        "  for t in range(n, N):\n",
        "    # get the n_gram preceding the word at position t\n",
        "    n_gram = sentence[t - n : t]\n",
        "\n",
        "    # get the word at position t\n",
        "    word = sentence[t]\n",
        "\n",
        "    # estimate the probability of the word given the n-gram using the n-gram counts, n-plus1-gram counts, vocabulary size and smoothing constant\n",
        "    probability = estimate_probability(word, n_gram, n_gram_counts, n_plus1_gram_counts, len(unique_words), k = 1)\n",
        "\n",
        "    # Update the product of the probabilities\n",
        "    # product_pi is the cumulative product of the (1/P) factors that are calculated in the loop\n",
        "    product_pi *= 1 / probability\n",
        "\n",
        "  # Take the N-th root of the product\n",
        "  perplexity = product_pi ** (1/float(N))\n",
        "\n",
        "  return perplexity "
      ],
      "metadata": {
        "id": "AsOKHO4EDv3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_perplexity(sentences, n_gram_counts, n_plus1_gram_counts, vocabulary_size, k = 1.0, batch_size = 1000):\n",
        "  batch_sum = 0\n",
        "  batch_mean = 0\n",
        "\n",
        "  total_batch_number = 0\n",
        "  total_batch_mean = 0\n",
        "  \n",
        "  for i, sentence in enumerate(sentences):\n",
        "    perplexity = calculate_perplexity(sentence, n_gram_counts_list[0], n_gram_counts_list[1], len(vocabulary), k = 1.0)\n",
        "    batch_sum += perplexity\n",
        "    if(i % batch_size == 0):\n",
        "      batch_mean = batch_sum / batch_size\n",
        "      batch_sum = 0\n",
        "\n",
        "      total_batch_mean += batch_mean\n",
        "      total_batch_number += 1\n",
        "\n",
        "      print(f\"Batch Number : {total_batch_number}, Batch mean : {batch_mean}\")\n",
        "\n",
        "  return total_batch_mean / total_batch_number"
      ],
      "metadata": {
        "id": "n37w34EFEBRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the perplexity of first test data\n",
        "perplexity_test = calculate_perplexity(test_data[0], n_gram_counts_list[0], n_gram_counts_list[1], len(vocabulary), k = 1.0)\n",
        "perplexity_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RTWoB_62TQD",
        "outputId": "71c7f60c-a184-4a9b-deb4-ca5afddc69ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50.08595909384548"
            ]
          },
          "metadata": {},
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity_test = mean_perplexity(test_data, n_gram_counts_list[0], n_gram_counts_list[1], len(vocabulary), k = 1.0)\n",
        "print(f\"Perplexity score of the model = {perplexity_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpLj4GRwEBI-",
        "outputId": "32b09c3b-8388-4b6c-87b5-d8fd6ce72806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Number : 1, Batch mean : 0.05008595909384548\n",
            "Batch Number : 2, Batch mean : 68.35781423300575\n",
            "Batch Number : 3, Batch mean : 68.72769120030458\n",
            "Batch Number : 4, Batch mean : 67.67094889782824\n",
            "Batch Number : 5, Batch mean : 69.22619189258396\n",
            "Batch Number : 6, Batch mean : 65.60438159287989\n",
            "Batch Number : 7, Batch mean : 67.90845419073437\n",
            "Batch Number : 8, Batch mean : 68.79992890053272\n",
            "Batch Number : 9, Batch mean : 68.34954337544801\n",
            "Batch Number : 10, Batch mean : 68.87837396706504\n",
            "Batch Number : 11, Batch mean : 66.51625779622\n",
            "Batch Number : 12, Batch mean : 70.48759558869985\n",
            "Batch Number : 13, Batch mean : 67.27051085202211\n",
            "Batch Number : 14, Batch mean : 67.85724720682443\n",
            "Batch Number : 15, Batch mean : 68.010417911914\n",
            "Batch Number : 16, Batch mean : 68.64593619837987\n",
            "Batch Number : 17, Batch mean : 68.97213384060413\n",
            "Batch Number : 18, Batch mean : 67.83659169911365\n",
            "Batch Number : 19, Batch mean : 68.17402582099915\n",
            "Batch Number : 20, Batch mean : 69.22088996587496\n",
            "Perplexity score of the model = 64.82825105450642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QajutcKSEA9e",
        "outputId": "84f62ca6-0101-4ac9-f2bc-5a143e07e787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ऐलानी', 'जग्गामा', 'बस्ने', 'उनीहरूसँग', 'लालपुर्जा']"
            ]
          },
          "metadata": {},
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0f08nEH1Siu",
        "outputId": "44381042-424d-451f-a1ce-ff5bcea1eea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['ना', 'ख', 'नम्बरको', 'बाह्र', 'चक्के', 'ट्रकले', 'पैदल', 'हिँड्दै', 'गरेका', 'सोही', 'ठाउँमा', 'वर्षीय', 'चन्द्रमान', 'श्रेष्ठलाई', 'ठक्कर', 'दिँदा', 'उनको', 'घटनास्थलमै', 'ज्यान', 'गएको', 'ट्राफिक', 'प्रमुख', 'दयाराम', 'पौडेलले', 'बताए'], ['कुर्सी', 'जलाएपछि', 'जिल्ला', 'प्रहरी', 'कार्यालयको', 'टोलीले', 'संगठनका', 'पूर्व', 'जिल्ला', 'इन्चार्ज', 'सीके', 'भट्ट', 'र', 'वर्तमान', 'इन्चार्ज', 'भीम', 'भट्टलाई', 'गिरफ्तार', 'गरेको', 'छ'], ['दृढ', 'इच्छा', 'शक्ति', 'हुनुपर्छ', 'जनकपुरलाई', 'आधुनिक', 'सहर', 'बनाउन', 'सम्भव', 'छ'], ['यो', 'त', 'व्यक्तिका', 'लागि', 'व्यक्तिले', 'गर्ने', 'नितान्त', 'नीजी', 'मामला', 'हो'], ['अंग्रेजहरु', 'भारतमा', 'आउँदा', 'नबाबहरु', 'यति', 'कमजोर', 'हुन', 'थाले', 'कि', 'अब', 'हामी', 'शासन', 'गर्न', 'सक्दैनौँ', 'भन्ने', 'लाग्न', 'थाल्यो']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u8BQ26QT6FLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3304c864-70eb-44ce-d262-502e79d3337d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sGH21VzFEjnQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}